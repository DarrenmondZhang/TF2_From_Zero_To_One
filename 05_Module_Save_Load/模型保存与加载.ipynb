{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  保存模型权重\n",
    "    * 方法一：保存checkpoint模型权重\n",
    "\n",
    "* 保存整个模型\n",
    "    * 方法二：保存HDF5文件（model.save)\n",
    "    * 方法三：保存pb文件（tf.saved_model)\n",
    "\n",
    "`saved_model`格式的模型可以直接用来预测(predict)，但是`saved_model`没有保存优化器配置\n",
    "\n",
    "\n",
    "方法一仅仅保存了模型中的权重`weights`。\n",
    "\n",
    "方法二模型和优化器都可以一起保存，包括权重`weights`、模型配置`architecture`和优化器配置`optimizer configuration`。这样做的好处是，当你恢复模型时，完全不依赖于原来搭建模型的代码。\n",
    "\n",
    "保存完整的模型有很多应用场景，比如在浏览器中使用`TensorFlow.js`加载运行，比如在移动设备上使用`TensorFlow Lite`加载运行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras版本模型保存与加载\n",
    "\n",
    "## 保存模型与加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "x_train = np.random.random((1000, 32))\n",
    "y_train = np.random.randint(10, size=(1000, ))\n",
    "x_val = np.random.random((200, 32))\n",
    "y_val = np.random.randint(10, size=(200, ))\n",
    "x_test = np.random.random((200, 32))\n",
    "y_test = np.random.randint(10, size=(200, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = tf.keras.Input(shape=(32,), name='digits')\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "    outputs = tf.keras.layers.Dense(10, name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/5\n32/32 [==============================] - 0s 12ms/step - loss: 2.3145 - sparse_categorical_accuracy: 0.1130 - val_loss: 2.3135 - val_sparse_categorical_accuracy: 0.1250\nEpoch 2/5\n32/32 [==============================] - 0s 12ms/step - loss: 2.2932 - sparse_categorical_accuracy: 0.1290 - val_loss: 2.3150 - val_sparse_categorical_accuracy: 0.1150\nEpoch 3/5\n32/32 [==============================] - 0s 11ms/step - loss: 2.2838 - sparse_categorical_accuracy: 0.1370 - val_loss: 2.3205 - val_sparse_categorical_accuracy: 0.1150\nEpoch 4/5\n32/32 [==============================] - 0s 12ms/step - loss: 2.2743 - sparse_categorical_accuracy: 0.1400 - val_loss: 2.3209 - val_sparse_categorical_accuracy: 0.1100\nEpoch 5/5\n32/32 [==============================] - 0s 11ms/step - loss: 2.2686 - sparse_categorical_accuracy: 0.1480 - val_loss: 2.3172 - val_sparse_categorical_accuracy: 0.1050\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2b870ffc1dd0>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndigits (InputLayer)          [(None, 32)]              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                2112      \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                4160      \n_________________________________________________________________\npredictions (Dense)          (None, 10)                650       \n=================================================================\nTotal params: 6,922\nTrainable params: 6,922\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法一：只保存模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.09758011, -0.29240972,  0.00580879, ..., -0.01371074,\n         0.1409894 ,  0.07672058],\n       [-0.10715104, -0.21462788,  0.15357468, ...,  0.31914845,\n        -0.05570589,  0.05032081],\n       [-0.27643338,  0.00062132,  0.1903002 , ...,  0.33042702,\n        -0.19873689, -0.03292914],\n       ...,\n       [-0.3375801 , -0.01842131,  0.28875068, ...,  0.2708185 ,\n         0.03702889, -0.20298825],\n       [-0.28116122, -0.18865623,  0.04680794, ...,  0.19834816,\n        -0.15128046, -0.03563374],\n       [-0.0989755 , -0.1609053 , -0.17766795, ...,  0.39745232,\n        -0.02683462, -0.17697851]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# model.save_weights(\"adasd.h5\")\n",
    "model.load_weights(\"adasd.h5\")\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "        -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "       [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "        -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "       [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "        -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "       ...,\n",
       "       [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "        -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "       [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "        -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "       [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "         1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/mannul_checkpoint')\n",
    "model.load_weights('./checkpoints/mannul_checkpoint')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法二：保存为pb文件类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: keras_model_tf_version\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "        -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "       [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "        -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "       [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "        -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "       ...,\n",
       "       [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "        -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "       [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "        -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "       [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "         1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the model to a SavedModel\n",
    "model.save('keras_model_tf_version', save_format='tf')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = tf.keras.models.load_model('keras_model_tf_version')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法三：保存HDF5方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "        -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "       [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "        -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "       [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "        -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "       ...,\n",
       "       [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "        -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "       [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "        -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "       [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "         1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save('keras_model_hdf5_version.h5')\n",
    "\n",
    "new_model = tf.keras.models.load_model('keras_model_hdf5_version.h5')\n",
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法四：常用于模型部署工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_saved_model_version\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'tf_saved_model_version')\n",
    "restored_saved_model = tf.saved_model.load('tf_saved_model_version')\n",
    "f = restored_saved_model.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': <tf.Tensor: id=7078, shape=(200, 10), dtype=float32, numpy=\n",
       " array([[-4.79599386e-01, -7.43045211e-02,  7.53526539e-02, ...,\n",
       "         -8.08903947e-02, -1.06541492e-01, -3.22730273e-01],\n",
       "        [-5.08367836e-01,  6.64272159e-02, -1.10150121e-01, ...,\n",
       "         -4.87524122e-02, -6.12244979e-02, -1.91938639e-01],\n",
       "        [-4.95316148e-01, -6.19690008e-02, -1.09398998e-01, ...,\n",
       "         -8.34675655e-02, -3.04364841e-02, -5.39932489e-01],\n",
       "        ...,\n",
       "        [-4.46070462e-01, -1.25298537e-02, -1.24217890e-01, ...,\n",
       "         -2.40157470e-02,  1.12229452e-01, -5.20460844e-01],\n",
       "        [-5.37934184e-01, -1.61610134e-02, -1.42415054e-04, ...,\n",
       "         -8.50361120e-03, -5.21083474e-02, -1.48310274e-01],\n",
       "        [-3.90737444e-01,  1.99008718e-01,  1.61002487e-01, ...,\n",
       "          1.07340984e-01,  1.46755893e-02, -4.48317945e-01]], dtype=float32)>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(digits = tf.constant(x_test.tolist()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['digits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 32)\n",
      "        name: serving_default_digits:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['predictions'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 13:44:40.779279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir tf_saved_model_version --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义版本模型保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        # 定义自己需要的层\n",
    "        self.dense_1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense_2 = tf.keras.layers.Dense(num_classes)\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None,32], tf.float32, name='digits')])\n",
    "    def call(self, inputs):\n",
    "        #定义前向传播\n",
    "        # 使用在 (in `__init__`)定义的层\n",
    "        x = self.dense_1(inputs)\n",
    "        return self.dense_2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = np.random.random((1000, 32))\n",
    "y_train = np.random.random((1000, 10))\n",
    "x_val = np.random.random((200, 32))\n",
    "y_val = np.random.random((200, 10))\n",
    "x_test = np.random.random((200, 32))\n",
    "y_test = np.random.random((200, 10))\n",
    "\n",
    "# 优化器\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "# 损失函数\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# 准备metrics函数\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# 准备训练数据集\n",
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# 准备测试数据集\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Training loss (for one batch) at step 0: 11.784499168395996\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.10300000011920929\n",
      "Validation acc: 0.12999999523162842\n",
      "Start of epoch 1\n",
      "Training loss (for one batch) at step 0: 12.349384307861328\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.10300000011920929\n",
      "Validation acc: 0.12999999523162842\n",
      "Start of epoch 2\n",
      "Training loss (for one batch) at step 0: 12.48736572265625\n",
      "Seen so far: 64 samples\n",
      "Training acc over epoch: 0.10300000011920929\n",
      "Validation acc: 0.12999999523162842\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(num_classes=10)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    # 遍历数据集的batch_size\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # 更新训练集的metrics\n",
    "        train_acc_metric(y_batch_train, logits)\n",
    "\n",
    "        # 每200 batches打印一次.\n",
    "        if step % 200 == 0:\n",
    "            print('Training loss (for one batch) at step %s: %s' % (step, float(loss_value)))\n",
    "            print('Seen so far: %s samples' % ((step + 1) * 64))\n",
    "\n",
    "    # 在每个epoch结束时显示metrics。\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print('Training acc over epoch: %s' % (float(train_acc),))\n",
    "    # 在每个epoch结束时重置训练指标\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # 在每个epoch结束时运行一个验证集。\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val)\n",
    "        # 更新验证集merics\n",
    "        val_acc_metric(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print('Validation acc: %s' % (float(val_acc),))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存方法一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59265125,  0.12652864,  0.50779265, ...,  0.38236466,\n",
       "        -0.48236898, -0.29403484],\n",
       "       [ 0.3201392 ,  0.31926885,  0.5004305 , ...,  0.34327263,\n",
       "        -0.46210355, -0.29095772],\n",
       "       [ 0.17330498,  0.5561173 ,  0.46075135, ...,  0.31273955,\n",
       "        -0.14429614, -0.6220318 ],\n",
       "       ...,\n",
       "       [ 0.45052963,  0.07747109,  0.4848441 , ...,  0.1167865 ,\n",
       "        -0.53735   , -0.03418449],\n",
       "       [ 0.2759326 ,  0.5026181 ,  0.52613723, ...,  0.0728192 ,\n",
       "        -0.3806155 , -0.19111347],\n",
       "       [ 0.62080455,  1.1130711 ,  0.523637  , ...,  0.31726438,\n",
       "        -0.10991763, -0.76191264]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"adasd.h5\")\n",
    "model.load_weights(\"adasd.h5\")\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59265125,  0.12652864,  0.50779265, ...,  0.38236466,\n",
       "        -0.48236898, -0.29403484],\n",
       "       [ 0.3201392 ,  0.31926885,  0.5004305 , ...,  0.34327263,\n",
       "        -0.46210355, -0.29095772],\n",
       "       [ 0.17330498,  0.5561173 ,  0.46075135, ...,  0.31273955,\n",
       "        -0.14429614, -0.6220318 ],\n",
       "       ...,\n",
       "       [ 0.45052963,  0.07747109,  0.4848441 , ...,  0.1167865 ,\n",
       "        -0.53735   , -0.03418449],\n",
       "       [ 0.2759326 ,  0.5026181 ,  0.52613723, ...,  0.0728192 ,\n",
       "        -0.3806155 , -0.19111347],\n",
       "       [ 0.62080455,  1.1130711 ,  0.523637  , ...,  0.31726438,\n",
       "        -0.10991763, -0.76191264]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/mannul_checkpoint')\n",
    "model.load_weights('./checkpoints/mannul_checkpoint')\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存方法二"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('my_saved_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model = tf.keras.models.load_model('my_saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存方法三"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('path_to_my_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('path_to_my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59265125,  0.12652864,  0.50779265, ...,  0.38236466,\n",
       "        -0.48236898, -0.29403484],\n",
       "       [ 0.3201392 ,  0.31926885,  0.5004305 , ...,  0.34327263,\n",
       "        -0.46210355, -0.29095772],\n",
       "       [ 0.17330498,  0.5561173 ,  0.46075135, ...,  0.31273955,\n",
       "        -0.14429614, -0.6220318 ],\n",
       "       ...,\n",
       "       [ 0.45052963,  0.07747109,  0.4848441 , ...,  0.1167865 ,\n",
       "        -0.53735   , -0.03418449],\n",
       "       [ 0.2759326 ,  0.5026181 ,  0.52613723, ...,  0.0728192 ,\n",
       "        -0.3806155 , -0.19111347],\n",
       "       [ 0.62080455,  1.1130711 ,  0.523637  , ...,  0.31726438,\n",
       "        -0.10991763, -0.76191264]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存方法四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.MyModel object at 0x0000020981C30C18>, because its inputs are not defined.\n",
      "INFO:tensorflow:Assets written to: my_saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, 'my_saved_model')\n",
    "restored_saved_model = tf.saved_model.load('my_saved_model')  # 没有保存优化器，所以不能直接用predict直接进行预测\n",
    "f = restored_saved_model.signatures[\"serving_default\"]  # 通过下面第二段的代码，查找对应的字段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_0': <tf.Tensor: id=20472, shape=(200, 10), dtype=float32, numpy=\n",
       " array([[0.36048555, 0.77584916, 0.5105363 , ..., 0.31300798, 0.15851551,\n",
       "         0.9504347 ],\n",
       "        [0.8945647 , 0.5531711 , 0.34847912, ..., 0.6248529 , 0.36228454,\n",
       "         1.1269959 ],\n",
       "        [0.12759946, 0.53442717, 0.7764567 , ..., 0.05553574, 0.31748763,\n",
       "         0.6228047 ],\n",
       "        ...,\n",
       "        [0.59310085, 0.6587581 , 0.19269958, ..., 0.47064906, 0.3493078 ,\n",
       "         0.650242  ],\n",
       "        [0.18195015, 0.9256924 , 0.9149718 , ..., 0.34724298, 0.24400793,\n",
       "         1.0152355 ],\n",
       "        [0.39257365, 0.8122336 , 1.0617772 , ..., 0.25777856, 0.25043324,\n",
       "         0.7244146 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(digits = tf.constant(x_test.tolist()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['digits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 32)\n",
      "        name: serving_default_digits:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-19 13:52:56.496039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir my_saved_model --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x_test.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa  = list(map(lambda x: int(x),a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(digits = tf.constant([aa]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "\n",
    "Keras版本保存模型:\n",
    "* `model.save_weights`（保存模型权重）\n",
    "* `model.save`（保存模型，本地加载，可保存为h5或者pb格式文件）\n",
    "* `tf.saved_model.save`（模型部署）\n",
    "\n",
    "\n",
    "Keras版本加载模型:\n",
    "* `model.load_weights` （加载模型权重）\n",
    "* `tf.keras.models.load_model` （加载h5或者pb文件）\n",
    "* `tf.saved_model.load` （加载模型部署文件）\n",
    "\n",
    "\n",
    "自定义模型版本保存模型:\n",
    "* `model.save_weights` (保存模型权重）\n",
    "* `tf.saved_model.save`（模型部署)\n",
    "* `model.save`（保存模型，本地加载，可保存为pb格式文件)\n",
    "\n",
    "自定义模型版本加载模型:\n",
    "* `model.load_weights` (加载模型权重)\n",
    "* `tf.saved_model.load`（加载模型部署文件)\n",
    "* `tf.keras.models.load_model` (加载pb文件)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}